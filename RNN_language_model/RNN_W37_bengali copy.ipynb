{"cells":[{"cell_type":"markdown","metadata":{"id":"chtchWUmLsmj"},"source":["## Imports and installs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-1oSppzjuE9"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19073,"status":"ok","timestamp":1698173818408,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"qwosR4Pyj6SL","outputId":"031ff65a-4a9e-4d03-a0c4-9a49587b37c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5IhBNBNj8Bp"},"outputs":[],"source":["%%capture\n","if IN_COLAB:\n","  !pip install nltk\n","  !pip install transformers\n","  !pip install translators\n","  !pip install datasets\n","  !pip install langdetect\n","  !python -m spacy download en_core_web_sm\n","  !python -m spacy download en_core_web_trf\n","  !pip install bpemb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7557,"status":"ok","timestamp":1698173911187,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"jm-gjQZIIad7","outputId":"4132a39a-92de-4fdb-b42a-b4b0ebf9f135"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using region  server backend.\n","\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd\n","from datasets import load_dataset\n","from datasets import load_from_disk\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import string\n","import spacy\n","from tqdm import tqdm\n","import translators as ts\n","from langdetect import detect\n","import random\n","import abc\n","import math\n","import collections\n","from collections import defaultdict\n","import regex as re\n","import pickle\n","# nltk imports\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import SnowballStemmer\n","from nltk import word_tokenize\n","from nltk.tokenize import WhitespaceTokenizer\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","# pytorch\n","import torch\n","import torchtext\n","# Setting torch device\n","device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","# BPE\n","from bpemb import BPEmb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1698173911797,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"2KxzJ2VEqxU-","outputId":"bcdbd5aa-bcd3-479b-c768-d9da191e47bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MASTERS KU/AUTUMN 2023/NLP/Week 37\n"]}],"source":["%cd '/content/drive/MyDrive/MASTERS KU/AUTUMN 2023/NLP/Week 37'"]},{"cell_type":"markdown","metadata":{"id":"hoX9-KgosBEn"},"source":["## Local imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PU27GOa6sAMy"},"outputs":[],"source":["from utils import *\n","from model_rnn import NextWordPredictor\n","from model_rnn import *"]},{"cell_type":"markdown","metadata":{"id":"h1Vvc8C4Lyjv"},"source":["## Loading and saving datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOYavwTh4sSW"},"outputs":[],"source":["# Saving\n","#train.save_to_disk('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/tydiqa/train')\n","#val.save_to_disk('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/tydiqa/validation')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xKtSJL15WFt"},"outputs":[],"source":["# Loading\n","train = load_from_disk('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/tydiqa/train')\n","val = load_from_disk('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/tydiqa/validation')\n"]},{"cell_type":"markdown","metadata":{"id":"4IY_6ieSL1iC"},"source":["## Initial preprocessing of datasets:\n","- Spliting into train and val\n","- Splitting into languages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y12bkAEekIWy"},"outputs":[],"source":["train_df = pd.DataFrame(train)\n","val_df = pd.DataFrame(val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92nIvzIKkLEM"},"outputs":[],"source":["bengali_train = get_df_lang(train_df, 'bengali')\n","arabic_train = get_df_lang(train_df, 'arabic')\n","indonesian_train = get_df_lang(train_df, 'indonesian')\n","\n","bengali_val = get_df_lang(val_df, 'bengali')\n","arabic_val = get_df_lang(val_df, 'arabic')\n","indonesian_val = get_df_lang(val_df, 'indonesian')"]},{"cell_type":"markdown","source":["# Using 'questions' as features"],"metadata":{"id":"v0q7JELKOf6O"}},{"cell_type":"markdown","source":["## Retrieving answer text"],"metadata":{"id":"ks0u1VXg_ULz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1698173941249,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"wYHx28i_Oixc","outputId":"fb522e5e-b8cd-424c-ef92-5fbb72be199b"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-271526598895>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  indonesian_train_columns['answer_text'] = indonesian_train_columns['annotations'].apply(custom_function) # answers train\n","<ipython-input-12-271526598895>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  indonesian_val_columns['answer_text'] = indonesian_val_columns['annotations'].apply(custom_function) # answers val\n","<ipython-input-12-271526598895>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  arabic_train_columns['answer_text'] = arabic_train_columns['annotations'].apply(custom_function) # answers train\n","<ipython-input-12-271526598895>:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  arabic_val_columns['answer_text'] = arabic_val_columns['annotations'].apply(custom_function) # answers val\n","<ipython-input-12-271526598895>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  bengali_train_columns['answer_text'] = bengali_train_columns['annotations'].apply(custom_function) # answers train\n","<ipython-input-12-271526598895>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  bengali_val_columns['answer_text'] = bengali_val_columns['annotations'].apply(custom_function) # answers val\n"]}],"source":["indonesian_train_columns = indonesian_train[['annotations', 'question_text','document_plaintext']]\n","indonesian_val_columns = indonesian_val[['annotations', 'question_text','document_plaintext']]\n","indonesian_train_columns['answer_text'] = indonesian_train_columns['annotations'].apply(custom_function) # answers train\n","indonesian_val_columns['answer_text'] = indonesian_val_columns['annotations'].apply(custom_function) # answers val\n","\n","arabic_train_columns = arabic_train[['annotations', 'question_text','document_plaintext']]\n","arabic_val_columns = arabic_val[['annotations', 'question_text','document_plaintext']]\n","arabic_train_columns['answer_text'] = arabic_train_columns['annotations'].apply(custom_function) # answers train\n","arabic_val_columns['answer_text'] = arabic_val_columns['annotations'].apply(custom_function) # answers val\n","\n","bengali_train_columns = bengali_train[['annotations', 'question_text','document_plaintext']]\n","bengali_val_columns = bengali_val[['annotations', 'question_text','document_plaintext']]\n","bengali_train_columns['answer_text'] = bengali_train_columns['annotations'].apply(custom_function) # answers train\n","bengali_val_columns['answer_text'] = bengali_val_columns['annotations'].apply(custom_function) # answers val"]},{"cell_type":"markdown","metadata":{"id":"UTNHxwXDkmZS"},"source":["# RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1698173941249,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"WSAvAJqzkndC","outputId":"7b5bf72b-452e-4563-ee6a-ddad1389a58c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":13}],"source":["# retrieved from course slides\n","def enforce_reproducibility(seed=42):\n","    # Sets seed manually for both CPU and CUDA\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # System based\n","    random.seed(seed)\n","    np.random.seed(seed)\n","enforce_reproducibility()\n","\n","device"]},{"cell_type":"markdown","metadata":{"id":"DC5aZRpRMDeg"},"source":["## Setting up the training and val corpuses (questions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Q6BiC9ZGooW"},"outputs":[],"source":["ben_corpus_val = bengali_val_columns['question_text'].to_list()\n","ben_corpus_train = bengali_train_columns['question_text'].to_list()\n","\n","arabic_corpus_train = arabic_train_columns['question_text'].to_list()\n","arabic_corpus_val = arabic_val_columns['question_text'].to_list()\n","\n","indonesian_corpus_train = indonesian_train_columns['question_text'].to_list()\n","indonesian_corpus_val = indonesian_val_columns['question_text'].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1698173941250,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"45T_PKcWFrOR","outputId":"fab19d77-698e-40b4-dcc6-d36da51cd636"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4779"]},"metadata":{},"execution_count":16}],"source":["len(ben_corpus_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":584,"status":"ok","timestamp":1698173941815,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"QHOu03HhFrEK","outputId":"b5d51195-2a8b-4b77-9432-caa56e5dc982"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["224"]},"metadata":{},"execution_count":17}],"source":["len(ben_corpus_val)"]},{"cell_type":"markdown","metadata":{"id":"EXdl_VLtMJKe"},"source":["## Building and saving/loading vocabulary"]},{"cell_type":"markdown","source":["### Building and saving vocabulary"],"metadata":{"id":"cAIOIuO5MM4a"}},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/MASTERS KU/AUTUMN 2023/NLP/Week 37/vocabs/bengali_questions_vocab.txt\"\n","\n","# This line of code builds the vocabulary with both the train and the validation corpuses\n","#total_vocabulary = build_vocab(ben_corpus_val + ben_corpus_train)\n","\n","# This line of code saves the string representation to a text file\n","#with open(file_path, \"w\") as file:\n","  #file.write(repr(total_vocabulary))\n"],"metadata":{"id":"hAwljHC8MMPO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading vocabulary"],"metadata":{"id":"HjTO9LGzMHM2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bx6qribcJ-LC"},"outputs":[],"source":["# This line of code reads the saved vocabulary\n","#with open(file_path, \"r\") as file:\n","    #list_str = file.read()\n","\n","# This line of code uses `eval` to parse the string into a list\n","#total_vocabulary = eval(list_str)"]},{"cell_type":"code","source":["print(len(total_vocabulary))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKH9KR7Y3_MX","executionInfo":{"status":"ok","timestamp":1698175803897,"user_tz":-120,"elapsed":38,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"a7e58c17-be68-41a6-f776-7c632e165a5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3749\n"]}]},{"cell_type":"markdown","source":["## Build embedding matrix"],"metadata":{"id":"vKFqXVh4rBvN"}},{"cell_type":"code","source":["# load the pretrained embeddings\n","bpemb_ar = BPEmb(lang='ar', dim=100, vs=25000) # arabic model\n","bpemb_ben = BPEmb(lang='bn', dim=100, vs=25000) # bengali model\n","bpemb_ind = BPEmb(lang='id', dim=100, vs=25000) # indonesian model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"er4FIprTrp96","executionInfo":{"status":"ok","timestamp":1698175803897,"user_tz":-120,"elapsed":23117,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"9442ccac-03e8-45ba-d811-b59e70997270"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading https://nlp.h-its.org/bpemb/ar/ar.wiki.bpe.vs25000.model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 742254/742254 [00:01<00:00, 741462.92B/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading https://nlp.h-its.org/bpemb/ar/ar.wiki.bpe.vs25000.d100.w2v.bin.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9491724/9491724 [00:02<00:00, 4727041.42B/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading https://nlp.h-its.org/bpemb/bn/bn.wiki.bpe.vs25000.model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 863227/863227 [00:01<00:00, 614118.83B/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading https://nlp.h-its.org/bpemb/bn/bn.wiki.bpe.vs25000.d100.w2v.bin.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9517491/9517491 [00:02<00:00, 4754752.32B/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading https://nlp.h-its.org/bpemb/id/id.wiki.bpe.vs25000.model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 650018/650018 [00:00<00:00, 814099.10B/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading https://nlp.h-its.org/bpemb/id/id.wiki.bpe.vs25000.d100.w2v.bin.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9465922/9465922 [00:02<00:00, 4316680.11B/s] \n"]}]},{"cell_type":"code","source":["#get the embedding matrix for our vocabulary\n","embedding_matrix, oov = create_embedding_matrix(total_vocabulary, bpemb_ben)"],"metadata":{"id":"sZh7UPsFq_sb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698175817836,"user_tz":-120,"elapsed":439,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"7be4a7ff-ab43-4015-846e-5b9ebfe74a6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["69.13843691651107 % of tokens are out of vocabulary\n"]}]},{"cell_type":"markdown","metadata":{"id":"3kvOeq9TZXIc"},"source":["## Parse the data and vectorize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2rZRQ26ZWUF"},"outputs":[],"source":["#train_features = [text_to_indices(x, total_vocabulary, lang='bengali') for x in ben_corpus_train]\n","#val_features = [text_to_indices(x, total_vocabulary, lang='bengali') for x in ben_corpus_val]"]},{"cell_type":"code","source":["#longest_text = max(train_features+val_features, key=len)\n","#max_length = len(longest_text)\n","#padding_index = 0\n","\n","# padding the feature vectors by applying the add_padding function to each text in the train and validation corpus\n","#train_features = [add_padding(x, max_length, padding_index) for x in train_features]\n","#val_features = [add_padding(x, max_length, padding_index) for x in val_features]"],"metadata":{"id":"rdbV_k-qrJtO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Saving features"],"metadata":{"id":"g1i36XF0L7Fm"}},{"cell_type":"code","source":["# These lines of code save the embedded features we just created\n","\n","#with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_questions_train_features.pkl', 'wb') as f:\n","    #pickle.dump(train_features, f)\n","\n","#with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_questions_val_features.pkl', 'wb') as f:\n","    #pickle.dump(val_features, f)"],"metadata":{"id":"-X7dlqRzKeUs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading features"],"metadata":{"id":"xMrM8LtYL9wX"}},{"cell_type":"code","source":["# These lines of code load the previously saved features\n","\n","with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_questions_train_features.pkl', 'rb') as f:\n","    train_features = pickle.load(f)\n","\n","with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_questions_val_features.pkl', 'rb') as f:\n","    val_features = pickle.load(f)"],"metadata":{"id":"x5Axo8uuKa1Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxX0dkliMPWL"},"source":["## Get inputs and targets by splitting sentences (window = 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31Mfi7r7w9uy"},"outputs":[],"source":["inputs = []\n","targets = []\n","for sentence in train_features:\n","  for feature in split_sentence(4,sentence,'bengali'):\n","    inputs.append(feature)\n","\n","  for target in split_sentence_target(4,sentence,'bengali'):\n","    targets.append(target)\n","\n","inputs_test = []\n","targets_test = []\n","for sentence in val_features:\n","  for feature in split_sentence(4,sentence,'bengali'):\n","\n","    inputs_test.append( feature)\n","  for target in  split_sentence_target(4,sentence,'bengali'):\n","    targets_test.append(target)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stow4x7GwrUJ"},"outputs":[],"source":["class PredictorTrain(torch.utils.data.Dataset):\n","    def __init__(self, features, labels):\n","        self.X = torch.LongTensor(features).type(torch.float32)\n","\n","        self.y = torch.from_numpy(np.array(labels)).type(torch.float32)\n","\n","    def __getitem__(self, index):\n","        X = self.X[index]\n","        y = self.y[index].unsqueeze(0)\n","        return X, y\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","num_classes = len(total_vocabulary)\n","\n","X_train = torch.tensor(inputs)  # input sequences (train)\n","y_train = torch.tensor(targets)\n","X_test = torch.tensor(inputs_test)  # input sequences (test)\n","y_test = torch.tensor(targets_test)\n","\n","\n","# Shuffle to avoid overfitting based in the sequence of inputs\n","num_samples = X_train.size(0)\n","shuffled_indices = torch.randperm(num_samples)\n","\n","# Use the shuffled indices to reorder both tensors\n","X_train_shuffled = X_train[shuffled_indices]\n","y_train_shuffled = y_train[shuffled_indices]\n","\n","\n","data_train = PredictorTrain(X_train_shuffled, y_train_shuffled) # this function takes train features and labels\n","data_val = PredictorTrain(X_test, y_test) # this function takes test features and labels\n","\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size=64)\n","val_loader = torch.utils.data.DataLoader(data_val, batch_size = 64)"]},{"cell_type":"markdown","source":["## Run the model"],"metadata":{"id":"71FHZLH4ofCW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZLdj_Uz3w1a"},"outputs":[],"source":["from model_rnn import training_loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPW66gJwxt6l"},"outputs":[],"source":["model = NextWordPredictor(rnn_size=100, vocab_size=len(total_vocabulary),embedding_matrix=embedding_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aXWMfSRshwa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698177526039,"user_tz":-120,"elapsed":10,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"32c828e2-830f-40bb-a04e-690591874cfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["NextWordPredictor(\n","  (rnn): RNN(4, 100, batch_first=True)\n","  (fc_logits): Linear(in_features=100, out_features=3749, bias=True)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPm8nzhzllHZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698177713328,"user_tz":-120,"elapsed":187297,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"fc5800ac-f739-42d7-f069-60cf56b68c28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: loss 7.588558952821383\n","Epoch 2: loss 7.57173035744103\n","Epoch 3: loss 7.57155711070464\n","Epoch 4: loss 7.572176210113132\n","Epoch 5: loss 7.571852297728523\n","Epoch 6: loss 7.571265943817532\n","Epoch 7: loss 7.571385404173549\n","Epoch 8: loss 7.571088767725462\n","Epoch 9: loss 7.571277988861265\n","Epoch 10: loss 7.571768843424338\n"]}],"source":["model = training_loop(model,10, train_loader) #training the model\n","output_probs = model.forward(X_train_shuffled) # generate outputs and evaluate the trained model\n","outputs = evaluate(model,val_loader)\n"]},{"cell_type":"markdown","source":["## Get predictions"],"metadata":{"id":"ZpKZ0osToh8d"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8eKbJI00FRW"},"outputs":[],"source":["def get_prediction(total_vocabulary,output):\n","  highest_value = torch.max(output)\n","  position = torch.where(output==highest_value)\n","  if len(position[0]) >0:\n","\n","    return total_vocabulary[position[0].item()]\n","  return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRjqhmY30y7N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698177713329,"user_tz":-120,"elapsed":31,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"de977f36-0a39-4dc2-92e9-ecb0a984e4f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["?\n","?\n","[unk]\n","?\n","?\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[unk]\n","[unk]\n","?\n","?\n","?\n","?\n","?\n","?\n"]}],"source":["for output in outputs:\n","  print(get_prediction(total_vocabulary,output))"]},{"cell_type":"markdown","source":["## Saving the model"],"metadata":{"id":"spkJWL4LNV6M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mk3jjjdw1mUC"},"outputs":[],"source":["# this line of code saves the model\n","#torch.save(model.state_dict(), '/content/drive/MyDrive/MASTERS KU/AUTUMN 2023/NLP/Week 37/weights/rnn_bengali_questions_weights.pth')"]},{"cell_type":"markdown","source":["## Looking at class distribution to understand predictions"],"metadata":{"id":"VK5s4T9HN-jg"}},{"cell_type":"code","source":["counted_numbers = Counter(targets)\n","# Sort the items in descending order based on their counts\n","sorted_numbers = sorted(counted_numbers.items(), key=lambda x: x[1], reverse=True)\n","sorted_numbers = sorted_numbers[0:5]\n","# Print the counts\n","for number, count in sorted_numbers:\n","    print(f\"{number}: {count} times, which corresponds to token: \", total_vocabulary[number])"],"metadata":{"id":"h1YLsQCiODq3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698177715266,"user_tz":-120,"elapsed":35,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"4944c988-c6c0-4090-ac19-ea12e345d88f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0: 79587 times, which corresponds to token:  \n","1095: 4777 times, which corresponds to token:  ?\n","1096: 2894 times, which corresponds to token:  [unk]\n","1646: 944 times, which corresponds to token:  কী\n","1536: 906 times, which corresponds to token:  কত\n"]}]},{"cell_type":"markdown","metadata":{"id":"_s4BIwEis-ze"},"source":["# Using 'document_plaintext' as features"]},{"cell_type":"markdown","source":["## Local imports"],"metadata":{"id":"GHo_Vyr6OVDa"}},{"cell_type":"code","source":["from utils import *"],"metadata":{"id":"HFT04jYjOUBh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting up the training and val corpuses (document_plaintext)"],"metadata":{"id":"jJBagu_BolXy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjS_9pTPlpdj"},"outputs":[],"source":["arabic_corpus_train = arabic_train_columns['document_plaintext'].to_list()\n","arabic_corpus_val = arabic_val_columns['document_plaintext'].to_list()\n","\n","indonesian_corpus_train = indonesian_train_columns['document_plaintext'].to_list()\n","indonesian_corpus_val = indonesian_val_columns['document_plaintext'].to_list()\n","\n","bengali_doc_train = bengali_train_columns['document_plaintext'].to_list()\n","bengali_doc_val = bengali_train_columns['document_plaintext'].to_list()"]},{"cell_type":"markdown","source":["## Subsetting the corpuses for computational ease"],"metadata":{"id":"C2AAyD9MNIr1"}},{"cell_type":"code","source":["bengali_doc_train = random.sample(bengali_doc_train, 200)\n","bengali_doc_val = random.sample(bengali_doc_val, 40)"],"metadata":{"id":"GszPk0KxNMIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(bengali_doc_train)"],"metadata":{"id":"q8fvzzz5Nh0z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698177715267,"user_tz":-120,"elapsed":28,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"95989ecd-5433-4cf8-f79a-e19de0c1c1af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["len(bengali_doc_val)"],"metadata":{"id":"KSjeggENNkbu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698177715844,"user_tz":-120,"elapsed":586,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"d96489a0-5395-4f2e-a34e-30b2ff1b1573"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["### Building and saving vocabulary"],"metadata":{"id":"0soumtCEMhGy"}},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/MASTERS KU/AUTUMN 2023/NLP/Week 37/vocabs/bengali_docs_vocab.txt\"\n","\n","# This line of code builds the vocabulary with both the train and the validation corpuses\n","#total_vocabulary = build_vocab(bengali_doc_train + bengali_doc_val)\n","\n","# This line of code saves the string representation to a text file\n","#with open(file_path, \"w\") as file:\n","  #file.write(repr(total_vocabulary))"],"metadata":{"id":"_S_Gw0c-Mkjp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading vocabulary"],"metadata":{"id":"lY7jpeb6MmuM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":884,"status":"ok","timestamp":1698177716723,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"oY5Ku2khHma3","outputId":"d6430809-5981-4f68-88ae-af27280f5b0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["6438\n"]}],"source":["# This line of code reads the saved vocabulary\n","with open(file_path, \"r\") as file:\n","    list_str = file.read()\n","\n","# This line of code uses `eval` to parse the string into a list\n","total_vocabulary = eval(list_str)\n","\n","print(len(total_vocabulary))"]},{"cell_type":"code","source":["#get the embedding matrix for the  vocabulary\n","embedding_matrix, oov = create_embedding_matrix(total_vocabulary, bpemb_ben)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVqYJZQ5VGCw","executionInfo":{"status":"ok","timestamp":1698177716724,"user_tz":-120,"elapsed":9,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"2695b1fd-b78e-45c1-ad47-70dc2aaaf181"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["72.50698974836905 % of tokens are out of vocabulary\n"]}]},{"cell_type":"markdown","source":["## Parse the data and vectorize"],"metadata":{"id":"N7Om5b7moxbh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUOJOmtatR-T"},"outputs":[],"source":["#train_features_doc = [text_to_indices(x, total_vocabulary, lang='bengali') for x in bengali_doc_train]\n","#val_features_doc = [text_to_indices(x, total_vocabulary, lang='bengali') for x in bengali_doc_val]"]},{"cell_type":"code","source":["#longest_text = max(train_features_doc+val_features_doc, key=len)\n","#max_length = len(longest_text)\n","#padding_index = 0\n","\n","# padding the feature vectors by applying the add_padding function to each text in the train and validation corpus\n","#train_features_doc = [add_padding(x, max_length, padding_index) for x in train_features_doc]\n","#val_features_doc = [add_padding(x, max_length, padding_index) for x in val_features_doc]"],"metadata":{"id":"6c21O3lATLyH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Saving the features"],"metadata":{"id":"pVSxnO_Wo8dk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIMtr_-fBoWr"},"outputs":[],"source":["# Save\n","#with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_docs_train_features.pkl', 'wb') as f:\n","    #pickle.dump(train_features_doc, f)\n","\n","#with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_docs_val_features.pkl', 'wb') as f:\n","    #pickle.dump(val_features_doc, f)"]},{"cell_type":"markdown","source":["### Loading the features"],"metadata":{"id":"16AkSMCOM5H6"}},{"cell_type":"code","source":["# Load\n","with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_docs_train_features.pkl', 'rb') as f:\n","    train_features_doc = pickle.load(f)\n","\n","with open('/content/drive/My Drive/MASTERS KU/AUTUMN 2023/NLP/Week 37/features/emb_bengali_docs_val_features.pkl', 'rb') as f:\n","    val_features_doc = pickle.load(f)"],"metadata":{"id":"afB1g2g8M6_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get inputs and targets by splitting sentences (window = 4)"],"metadata":{"id":"S4JgAl_vpKLx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTiOidwMtSg1"},"outputs":[],"source":["inputs_doc = []\n","targets_doc = []\n","for sentence in train_features_doc:\n","  for feature in split_sentence(4,sentence,'bengali'):\n","    inputs_doc.append(feature)\n","\n","  for target in  split_sentence_target(4,sentence,'bengali'):\n","    targets_doc.append(target)\n","\n","inputs_test_doc = []\n","targets_test_doc = []\n","for sentence in val_features_doc:\n","  for feature in split_sentence(4,sentence,'bengali'):\n","\n","    inputs_test_doc.append(feature)\n","  for target in  split_sentence_target(4,sentence,'bengali'):\n","    targets_test_doc.append(target)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gG_661KtrGi"},"outputs":[],"source":["class PredictorTrain(torch.utils.data.Dataset):\n","    def __init__(self, features, labels):\n","        self.X = torch.LongTensor(features).type(torch.float32)\n","\n","        self.y = torch.from_numpy(np.array(labels)).type(torch.float32)\n","\n","    def __getitem__(self, index):\n","        X = self.X[index]\n","        y = self.y[index].unsqueeze(0)\n","        return X, y\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","num_classes = len(total_vocabulary)\n","\n","X_train = torch.tensor(inputs_doc)  # input sequences (train)\n","y_train = torch.tensor(targets_doc)\n","X_test = torch.tensor(inputs_test_doc)  # input sequences (test)\n","y_test = torch.tensor(targets_test_doc)\n","\n","\n","# Shuffle to avoid overfitting based in the sequence of inputs\n","num_samples = X_train.size(0)\n","shuffled_indices = torch.randperm(num_samples)\n","X_train_shuffled = X_train[shuffled_indices]\n","y_train_shuffled = y_train[shuffled_indices]\n","\n","\n","data_train = PredictorTrain(X_train_shuffled, y_train_shuffled) # this function takes train features and labels\n","data_val = PredictorTrain(X_test, y_test) # this function takes test features and labels\n","\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size=64)\n","val_loader = torch.utils.data.DataLoader(data_val, batch_size = 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPR1JvqMZefh"},"outputs":[],"source":["from model_rnn import NextWordPredictor\n","from model_rnn import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6hkdEFVZefh"},"outputs":[],"source":["from model_rnn import training_loop"]},{"cell_type":"code","source":["model = NextWordPredictor(rnn_size=100, vocab_size=len(total_vocabulary), embedding_matrix=embedding_matrix)"],"metadata":{"id":"gN520IHm9SOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qc1_Z0eQAHQc","executionInfo":{"status":"ok","timestamp":1698177793571,"user_tz":-120,"elapsed":19,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"40e378c2-3289-4a6c-fa6d-de99b9bad783"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NextWordPredictor(\n","  (rnn): RNN(4, 100, batch_first=True)\n","  (fc_logits): Linear(in_features=100, out_features=6438, bias=True)\n",")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":198378,"status":"ok","timestamp":1698177991935,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"sei6SWYgtv4P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c16574b-e58f-4942-c069-59397da39e1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: loss 8.022043839298984\n","Epoch 2: loss 7.984240531921387\n","Epoch 3: loss 7.9814798602934225\n","Epoch 4: loss 7.981470536820384\n","Epoch 5: loss 7.981419946561509\n","Epoch 6: loss 7.981410040599708\n","Epoch 7: loss 7.981397965408172\n","Epoch 8: loss 7.981380777072401\n","Epoch 9: loss 7.981342724230828\n","Epoch 10: loss 7.98133451965323\n"]}],"source":["model_doc = training_loop(model,10, train_loader) #training the model\n","output_probs_doc = model_doc.forward(X_train) # generate outputs and evaluate the trained model\n","outputs_doc = evaluate( model_doc,val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":85,"status":"ok","timestamp":1698177991935,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"B3k6eK5PPXa9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7aa360a-eaea-42fa-f7f3-ccee845fc590"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([24, 6438])"]},"metadata":{},"execution_count":60}],"source":["outputs_doc.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":84,"status":"ok","timestamp":1698177991938,"user":{"displayName":"caro brasor","userId":"11459111551275974149"},"user_tz":-120},"id":"ZQZlHlx1t1F9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"34d97ef3-6e58-4da7-9daf-48345c6bfb4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n","।\n"]}],"source":["def get_prediction(total_vocabulary,output):\n","  highest_value = torch.max(output)\n","  position = torch.where(output==highest_value)\n","  if len(position[0]) >0:\n","\n","    return total_vocabulary[position[0].item()]\n","  return None\n","\n","for output in outputs_doc:\n","  print(get_prediction(total_vocabulary,output))"]},{"cell_type":"markdown","source":["## Saving the model"],"metadata":{"id":"IvoOtkAXNtAc"}},{"cell_type":"code","source":["# Saving the model\n","#torch.save(model.state_dict(), '/content/drive/MyDrive/MASTERS KU/AUTUMN 2023/NLP/Week 37/weights/rnn_bengali_documents_weights.pth')"],"metadata":{"id":"gzh7afT-gTFW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Looking at class distribution to understand the predictions"],"metadata":{"id":"aG84EsgyCeEi"}},{"cell_type":"code","source":["# Understanding how classes are distributed\n","\n","from collections import Counter\n","counted_numbers = Counter(targets_doc)\n","\n","# Sort the items in descending order based on their counts\n","sorted_numbers = sorted(counted_numbers.items(), key=lambda x: x[1], reverse=True)\n","sorted_numbers = sorted_numbers[0:5]\n","\n","# Print the counts\n","for number, count in sorted_numbers:\n","    print(f\"{number}: {count} times, which corresponds to token: \", total_vocabulary[number])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRZLPuBVxgzL","executionInfo":{"status":"ok","timestamp":1698177991939,"user_tz":-120,"elapsed":46,"user":{"displayName":"caro brasor","userId":"11459111551275974149"}},"outputId":"6dea7e9a-628d-400d-c74a-accb3e88fca3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0: 84610 times, which corresponds to token:  \n","2030: 1051 times, which corresponds to token:  ।\n","1713: 461 times, which corresponds to token:  ,\n","1519: 218 times, which corresponds to token:  ##ের\n","2752: 217 times, which corresponds to token:  ও\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1NmUddfQJL0n939i7ODpnV_3u6_tWDkhw","authorship_tag":"ABX9TyPwmtCoe6N94rCRKPYvwCVF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}